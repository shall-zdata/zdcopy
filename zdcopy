#!/bin/bash
# zdcopy  port to postgres
#
#
#

## GET USER INPUT
echo "What database would you like to extract?"
read pgdatabase
export PGDATABASE=$pgdatabase

echo "How many threads do you want to run:"
read threads
echo "What is the destination bucket example: s3://temp-bucket:"
read s3path

echo "What is your AWS API KEY"
read aws_key
echo $aws_key
AWS_ACCESS_KEY_ID=$aws_key

echo "What is your AWS Secret Key:"
read aws_secret_key
echo $aws_secret_key
AWS_SECRET_ACCESS_KEY=$aws_secret_key

echo "What AWS region is your bucket in:"
read region
AWS_DEFAULT_REGION=$region



# Get the tables
gpconnection="psql -o list.txt -t"
echo $gpconnection


$gpconnection <<SQL
SELECT 'psql -c "COPY ' || table_schema ||'.'||table_name || ' TO stdout ' ||' DELIMITER '';'' CSV HEADER;"' 
|| ' | gzip | ./copy2aws s3path/pgdatabase.'||table_schema ||'.' ||table_name ||'.csv.gz'
FROM information_schema.tables t INNER JOIN information_schema.schemata s 
ON s.schema_name = t.table_schema 
WHERE t.table_schema NOT IN ('gp_toolkit','pg_catalog', 'information_schema', 'configuration')
AND t.table_type NOT IN ('VIEW');
SQL

echo $filepath
# add path and database name to scripts
sed -i "s|s3path|$s3path|g" list.txt
sed -i "s|pgdatabase|$pgdatabase|g" list.txt

for exclude in $(cat exclude_list.txt); do
awk -v exclude="$exclude" '$0 !~ exclude {print $0}' list.txt > list2.txt
mv list2.txt list.txt
done

parallel --progress -j$threads < list.txt  

#rm list2.txt
#rm list.txxt






















